name: Run speed comparison

on:
  push:
    paths-ignore:
      - "**.md"
      - "assets/**"
      - "LICENSE"
      - ".gitignore"
      - ".gitattributes"
      - "docs/**"
    branches:
      - master
  pull_request:
    types: [opened, synchronize, labeled]
  pull_request_review:
    types: [submitted]
  issue_comment:
    types: [created]
  workflow_dispatch:
    inputs:
      build:
        description: 'Name of the earth build to run (e.g., "rust" or "rust go c")'
        required: false
        type: string
      full:
        description: "Run full benchmark suite"
        required: false
        type: boolean
        default: false

env:
  EARTHLY_VERSION: "0.8.15"

jobs:
  # Parse /bench commands from PR comments
  parse-comment:
    runs-on: ubuntu-latest
    if: github.event_name == 'issue_comment' && github.event.issue.pull_request && startsWith(github.event.comment.body, '/bench')
    outputs:
      languages: ${{ steps.parse.outputs.languages }}
      should_run: ${{ steps.parse.outputs.should_run }}
      show_help: ${{ steps.parse.outputs.show_help }}
      pr_ref: ${{ steps.get-pr.outputs.ref }}
      pr_sha: ${{ steps.get-pr.outputs.sha }}
      pr_repo: ${{ steps.get-pr.outputs.repo }}
      pr_number: ${{ steps.get-pr.outputs.pr_number }}
      changed_languages: ${{ steps.detect-changed.outputs.languages }}
    steps:
      - name: Check if comment author is repository owner
        id: check-permission
        run: |
          if [ "${{ github.event.comment.user.login }}" != "niklas-heer" ]; then
            echo "Comment author is not niklas-heer, skipping..."
            echo "authorized=false" >> $GITHUB_OUTPUT
          else
            echo "Comment author is niklas-heer, proceeding..."
            echo "authorized=true" >> $GITHUB_OUTPUT
          fi

      - name: Parse /bench command
        id: parse
        if: steps.check-permission.outputs.authorized == 'true'
        run: |
          COMMENT="${{ github.event.comment.body }}"
          LANGUAGES=$(echo "$COMMENT" | sed -n 's/^\/bench[[:space:]]*//p' | tr -s ' ' | xargs)

          if [ -z "$LANGUAGES" ]; then
            echo "No languages specified, will show help"
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "show_help=true" >> $GITHUB_OUTPUT
          elif [ "$LANGUAGES" = "help" ]; then
            echo "Help requested"
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "show_help=true" >> $GITHUB_OUTPUT
          elif [ "$LANGUAGES" = "changed" ]; then
            echo "Will benchmark changed languages"
            echo "should_run=changed" >> $GITHUB_OUTPUT
            echo "show_help=false" >> $GITHUB_OUTPUT
          else
            echo "Languages to benchmark: $LANGUAGES"
            echo "languages=$LANGUAGES" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "show_help=false" >> $GITHUB_OUTPUT
          fi

      - name: Get PR info
        id: get-pr
        if: steps.check-permission.outputs.authorized == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const pr = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            core.setOutput('ref', pr.data.head.ref);
            core.setOutput('sha', pr.data.head.sha);
            core.setOutput('repo', pr.data.head.repo.full_name);
            core.setOutput('pr_number', context.issue.number);

      - name: Detect changed languages
        id: detect-changed
        if: steps.parse.outputs.should_run == 'changed'
        uses: actions/github-script@v7
        with:
          script: |
            const files = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            const langPattern = /^src\/leibniz\.(\w+)$/;
            const earthfilePattern = /^Earthfile$/;
            const languages = new Set();

            for (const file of files.data) {
              // Check for leibniz.* source files
              const match = file.filename.match(langPattern);
              if (match) {
                // Map file extension to Earthfile target name
                const ext = match[1];
                languages.add(ext);
              }
            }

            const langList = Array.from(languages).join(' ');
            console.log(`Changed languages: ${langList}`);
            core.setOutput('languages', langList);

      - name: Show help
        if: steps.parse.outputs.show_help == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const helpText = `## /bench Command Help

**Usage:**
- \`/bench <language> [language2] ...\` - Benchmark specific languages
- \`/bench changed\` - Benchmark languages modified in this PR
- \`/bench help\` - Show this help message

**Examples:**
- \`/bench rust go c\` - Benchmark Rust, Go, and C
- \`/bench csharp fsharp\` - Benchmark C# and F#
- \`/bench changed\` - Auto-detect and benchmark changed languages

**Available languages:**
Run \`earthly ls\` locally or check the Earthfile for all targets.`;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: helpText
            });

      - name: Add reaction to comment
        if: steps.parse.outputs.should_run == 'true' || steps.parse.outputs.should_run == 'changed'
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.reactions.createForIssueComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: context.payload.comment.id,
              content: 'rocket'
            });

  # Run specific languages from /bench command
  bench-comment:
    needs: parse-comment
    if: needs.parse-comment.outputs.should_run == 'true' || needs.parse-comment.outputs.should_run == 'changed'
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
    steps:
      - name: Determine languages to benchmark
        id: langs
        run: |
          if [ "${{ needs.parse-comment.outputs.should_run }}" = "changed" ]; then
            LANGUAGES="${{ needs.parse-comment.outputs.changed_languages }}"
            if [ -z "$LANGUAGES" ]; then
              echo "No language files changed in this PR"
              echo "languages=" >> $GITHUB_OUTPUT
              echo "skip=true" >> $GITHUB_OUTPUT
            else
              echo "languages=$LANGUAGES" >> $GITHUB_OUTPUT
              echo "skip=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "languages=${{ needs.parse-comment.outputs.languages }}" >> $GITHUB_OUTPUT
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Create check run
        id: check
        if: steps.langs.outputs.skip != 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const check = await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'Benchmark: ${{ steps.langs.outputs.languages }}',
              head_sha: '${{ needs.parse-comment.outputs.pr_sha }}',
              status: 'in_progress',
              output: {
                title: 'Running benchmarks',
                summary: 'Benchmarking: `${{ steps.langs.outputs.languages }}`'
              }
            });
            core.setOutput('check_id', check.data.id);

      - name: Comment no changes
        if: steps.langs.outputs.skip == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: ${{ needs.parse-comment.outputs.pr_number }},
              body: '**No language source files changed in this PR.**\n\nUse `/bench <language>` to benchmark specific languages, or `/bench help` for more options.'
            });

      - uses: actions/checkout@v4
        if: steps.langs.outputs.skip != 'true'
        with:
          repository: ${{ needs.parse-comment.outputs.pr_repo }}
          ref: ${{ needs.parse-comment.outputs.pr_sha }}

      - name: Setup Earthly
        if: steps.langs.outputs.skip != 'true'
        uses: earthly/actions-setup@v1
        with:
          version: v${{ env.EARTHLY_VERSION }}

      - name: Run benchmarks for specified languages
        if: steps.langs.outputs.skip != 'true'
        id: bench
        run: |
          LANGUAGES="${{ steps.langs.outputs.languages }}"
          echo "Running benchmarks for: $LANGUAGES"
          FAILED=""
          for lang in $LANGUAGES; do
            echo "::group::Building +$lang"
            if ! earthly --ci +$lang; then
              FAILED="$FAILED $lang"
              echo "::error::Benchmark for $lang failed"
            fi
            echo "::endgroup::"
          done
          if [ -n "$FAILED" ]; then
            echo "failed=$FAILED" >> $GITHUB_OUTPUT
          fi

      - name: Analyze data
        if: steps.langs.outputs.skip != 'true'
        run: earthly --ci +analysis

      - name: Archive test results
        if: steps.langs.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: bench-results-${{ needs.parse-comment.outputs.pr_number }}
          path: |
            results/*.json
            results/*.csv
            results/*.png

      - name: Comment results on PR
        if: steps.langs.outputs.skip != 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const languages = '${{ steps.langs.outputs.languages }}';
            const failed = '${{ steps.bench.outputs.failed }}'.trim();

            let comment = '## Benchmark Results\n\n';
            comment += `**Languages tested:** \`${languages}\`\n`;
            comment += `**Commit:** \`${{ needs.parse-comment.outputs.pr_sha }}\`\n\n`;

            if (failed) {
              comment += `> **Warning:** Some benchmarks failed: \`${failed}\`\n\n`;
            }

            try {
              const csv = fs.readFileSync('results/combined_results.csv', 'utf8');
              const lines = csv.trim().split('\n');
              if (lines.length > 1) {
                comment += '| Language | Min | Median | Max | Accuracy |\n';
                comment += '|:---------|----:|-------:|----:|:--------:|\n';
                for (let i = 1; i < lines.length; i++) {
                  const cols = lines[i].split(',');
                  if (cols.length >= 5) {
                    const min = parseFloat(cols[1]).toFixed(1);
                    const median = parseFloat(cols[2]).toFixed(1);
                    const max = parseFloat(cols[3]).toFixed(1);
                    const accuracy = cols[4] ? cols[4].trim() : 'N/A';
                    comment += `| ${cols[0]} | ${min} ms | ${median} ms | ${max} ms | ${accuracy} |\n`;
                  }
                }
                comment += '\n';
              }
            } catch (e) {
              comment += '_Could not parse results CSV_\n\n';
            }

            comment += `<details>\n<summary>View artifacts and logs</summary>\n\n`;
            comment += `[View workflow run](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})\n`;
            comment += `</details>`;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: ${{ needs.parse-comment.outputs.pr_number }},
              body: comment
            });

      - name: Update check run
        if: always() && steps.check.outputs.check_id
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const failed = '${{ steps.bench.outputs.failed }}'.trim();
            const conclusion = failed ? 'failure' : 'success';

            let summary = '';
            try {
              const csv = fs.readFileSync('results/combined_results.csv', 'utf8');
              const lines = csv.trim().split('\n');
              if (lines.length > 1) {
                summary = '| Language | Median |\n|:---------|-------:|\n';
                for (let i = 1; i < lines.length; i++) {
                  const cols = lines[i].split(',');
                  if (cols.length >= 3) {
                    summary += `| ${cols[0]} | ${parseFloat(cols[2]).toFixed(1)} ms |\n`;
                  }
                }
              }
            } catch (e) {
              summary = 'Results not available';
            }

            await github.rest.checks.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              check_run_id: ${{ steps.check.outputs.check_id }},
              status: 'completed',
              conclusion: conclusion,
              output: {
                title: failed ? `Benchmarks completed with failures: ${failed}` : 'Benchmarks completed',
                summary: summary
              }
            });

  # Manual workflow dispatch - run specific languages
  check:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && inputs.build != ''
    steps:
      - uses: actions/checkout@v4

      - name: Setup Earthly
        uses: earthly/actions-setup@v1
        with:
          version: v${{ env.EARTHLY_VERSION }}

      - name: Run benchmarks
        run: |
          BUILDS="${{ inputs.build }}"
          for build in $BUILDS; do
            echo "::group::Building +$build"
            earthly --ci +$build
            echo "::endgroup::"
          done

      - name: Analyze data
        run: earthly --ci +analysis

      - name: Archive test results
        uses: actions/upload-artifact@v4
        with:
          name: combined-results
          path: |
            results/*.json
            results/*.csv
            results/*.png

  # Fast check for PRs - runs a small subset of languages
  fast-check:
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' &&
      github.event.action != 'labeled' &&
      !contains(github.event.pull_request.labels.*.name, 'skip-ci')
    steps:
      - uses: actions/checkout@v4

      - name: Setup Earthly
        uses: earthly/actions-setup@v1
        with:
          version: v${{ env.EARTHLY_VERSION }}

      - name: Run fast benchmark subset
        run: |
          echo "Running fast benchmark subset (c, go, rust, cpython)"
          earthly --ci +fast-check

      - name: Analyze data
        run: earthly --ci +analysis

      - name: Archive test results
        uses: actions/upload-artifact@v4
        with:
          name: fast-check-results
          path: |
            results/*.json
            results/*.csv
            results/*.png

  # Discover languages from Earthfile for matrix build
  discover:
    runs-on: ubuntu-latest
    if: |
      (github.ref == 'refs/heads/master' && github.event_name == 'push') ||
      github.event.review.state == 'approved' ||
      github.event.label.name == 'enable-ci' ||
      (github.event_name == 'workflow_dispatch' && inputs.full == true)
    outputs:
      languages: ${{ steps.discover.outputs.languages }}
    steps:
      - uses: actions/checkout@v4

      - name: Discover language targets
        id: discover
        run: |
          chmod +x ./scripts/discover-languages.sh
          LANGUAGES=$(./scripts/discover-languages.sh)
          echo "Discovered languages: $LANGUAGES"
          echo "languages=$LANGUAGES" >> $GITHUB_OUTPUT

  # Build scmeta tool once and share across all benchmark jobs
  # Uses cache to skip building if scmeta source hasn't changed
  build-scmeta:
    needs: discover
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Get scmeta source hash
        id: scmeta-hash
        run: |
          HASH=$(find scmeta -type f \( -name "*.cr" -o -name "shard.yml" -o -name "shard.lock" \) -exec sha256sum {} \; | sort | sha256sum | cut -d' ' -f1)
          echo "hash=$HASH" >> $GITHUB_OUTPUT
          echo "scmeta source hash: $HASH"

      - name: Cache scmeta binary
        id: cache-scmeta
        uses: actions/cache@v4
        with:
          path: scmeta-bin/scmeta
          key: scmeta-linux-x64-${{ steps.scmeta-hash.outputs.hash }}

      - name: Setup Earthly
        if: steps.cache-scmeta.outputs.cache-hit != 'true'
        uses: earthly/actions-setup@v1
        with:
          version: v${{ env.EARTHLY_VERSION }}

      - name: Build and export scmeta
        if: steps.cache-scmeta.outputs.cache-hit != 'true'
        run: earthly --ci --output +export-scmeta

      - name: Upload scmeta artifact
        uses: actions/upload-artifact@v4
        with:
          name: scmeta-binary
          path: scmeta-bin/scmeta
          retention-days: 1

  # Matrix build - run each language in parallel
  # Uses cache to skip benchmarks if source hasn't changed
  benchmark:
    needs: [discover, build-scmeta]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        language: ${{ fromJson(needs.discover.outputs.languages) }}
    steps:
      - uses: actions/checkout@v4

      - name: Get source file for ${{ matrix.language }}
        id: get-source
        run: |
          chmod +x ./scripts/get-source-file.sh
          SOURCE_PATH=$(./scripts/get-source-file.sh "${{ matrix.language }}")
          echo "source_path=$SOURCE_PATH" >> $GITHUB_OUTPUT
          echo "Source path for ${{ matrix.language }}: $SOURCE_PATH"

      - name: Compute cache key
        id: cache-key
        run: |
          # Hash the source file(s), Earthfile target section, and rounds.txt
          SOURCE_HASH=$(find ${{ steps.get-source.outputs.source_path }} -type f -exec sha256sum {} \; 2>/dev/null | sort | sha256sum | cut -d' ' -f1)
          # Extract the full target section (from "target:" until the next target or EOF)
          EARTHFILE_HASH=$(awk '/^${{ matrix.language }}:$/{found=1} found{print; if(/^[a-zA-Z][a-zA-Z0-9_-]*:$/ && !/^${{ matrix.language }}:$/) exit}' Earthfile | sha256sum | cut -d' ' -f1)
          ROUNDS_HASH=$(sha256sum src/rounds.txt | cut -d' ' -f1)
          COMBINED="${SOURCE_HASH}-${EARTHFILE_HASH}-${ROUNDS_HASH}"
          CACHE_KEY=$(echo "$COMBINED" | sha256sum | cut -d' ' -f1 | head -c 16)
          echo "key=$CACHE_KEY" >> $GITHUB_OUTPUT
          echo "Cache key for ${{ matrix.language }}: $CACHE_KEY"

      - name: Cache benchmark result
        id: cache-benchmark
        uses: actions/cache@v4
        with:
          path: results/${{ matrix.language }}.json
          key: benchmark-${{ matrix.language }}-${{ steps.cache-key.outputs.key }}

      - name: Download scmeta
        if: steps.cache-benchmark.outputs.cache-hit != 'true'
        uses: actions/download-artifact@v4
        with:
          name: scmeta-binary
          path: scmeta-bin

      - name: Setup scmeta
        if: steps.cache-benchmark.outputs.cache-hit != 'true'
        run: chmod +x scmeta-bin/scmeta

      - name: Setup Earthly
        if: steps.cache-benchmark.outputs.cache-hit != 'true'
        uses: earthly/actions-setup@v1
        with:
          version: v${{ env.EARTHLY_VERSION }}

      - name: Run benchmark for ${{ matrix.language }}
        if: steps.cache-benchmark.outputs.cache-hit != 'true'
        run: earthly --ci --output --build-arg USE_PREBUILT_SCMETA=true +${{ matrix.language }}

      - name: Show cache status
        run: |
          if [ "${{ steps.cache-benchmark.outputs.cache-hit }}" == "true" ]; then
            echo "âœ… Using cached result for ${{ matrix.language }}"
          else
            echo "ðŸ”¨ Ran fresh benchmark for ${{ matrix.language }}"
          fi

      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: result-${{ matrix.language }}
          path: results/${{ matrix.language }}.json
          retention-days: 1

  # Collect all results and run analysis
  analyze:
    needs: [discover, benchmark]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: result-*
          path: results-raw
          merge-multiple: false

      - name: Collect results
        run: |
          mkdir -p results
          find results-raw -name "*.json" -exec cp {} results/ \;
          echo "Collected results:"
          ls -la results/

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -e .

      - name: Run analysis
        run: python analyze.py --folder ./results/ --out ./results/ --rounds ./src/rounds.txt

      - name: Archive combined results
        uses: actions/upload-artifact@v4
        with:
          name: combined-results
          path: |
            results/*.json
            results/*.csv
            results/*.png

  # Publish results to GitHub Pages
  publish:
    needs: analyze
    if: github.ref == 'refs/heads/master' && github.event_name != 'pull_request'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: results

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Publish to docs
        run: |
          python publish.py --results ./results --docs ./docs
          echo "Published results to docs folder" >> $GITHUB_STEP_SUMMARY

      - name: Commit and push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "docs: update benchmark results"
          file_pattern: "docs/history/**"
